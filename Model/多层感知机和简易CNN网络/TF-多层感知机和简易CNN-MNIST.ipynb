{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)# 2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取数据集\n",
    "from tensorflow.keras.datasets import mnist\n",
    "#from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接下载数据或出现HTTP连接超时 开了加速器仍然会有问题 但是可以打开出错消息里面\n",
    "# 的网址下载数据再将数据放到C:\\Users\\Administrator\\.keras\\datasets文件夹下\n",
    "# 即可\n",
    "(train_data, train_label), (test_data, test_label) = mnist.load_data('./mnist.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多层感知机\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 定义模型\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "tensorflow中tf.keras.models.Sequential()用法:\n",
    "Sequential()方法是一个容器，描述了神经网络的网络结构，在Sequential()的输入参数\n",
    "中描述从输入层到输出层的网络结构。\n",
    "\n",
    "拉直层：tf.keras.layers.Flatten()\n",
    "tf.keras.layers.Flatten(\n",
    "    data_format=None, **kwargs\n",
    ")\n",
    "可以变换张量的尺寸，把输入特征拉直为一维数组，是不含计算参数的层\n",
    "\n",
    "全连接层：tf.keras.layers.Dense\n",
    "tf.keras.layers.Dense(\n",
    "    units=10,  # 输出的维度大小\n",
    "    activation=None,  # 选择使用的（激活函数）\n",
    "    use_bias=True,  # 是否使用（偏置项）\n",
    "    kernel_initializer=None,  # 卷积核的初始化器\n",
    "    bias_initializer=tf.zeros_initializer(),  # 偏置项的初始化器\n",
    "    kernel_regularizer=None,  # 卷积核的正则化\n",
    "    bias_regularizer=None, # 偏置项的正则化\n",
    "    activaty_regularizer=None, # 输出层的激活函数的正则化 \n",
    "    kernel_constraint=None,  # 对主权重矩阵进行约束\n",
    "    bias_constraint=None,  # 对偏置向量进行约束\n",
    "    **kwargs\n",
    ")\n",
    "#activation可选 relu 、softmax、 sigmoid、 tanh等\n",
    "#kernel_regularizer可选 tf.keras.regularizers.l1() 、tf.keras.regularizers.l2()\n",
    "\n",
    "卷积层：tf.keras.layers.Conv2D\n",
    "tf.keras.layers.Conv2D(\n",
    "    filters, # 卷积过滤器的数量,对应输出的维数\n",
    "    kernel_size, # 整数,过滤器的大小,如果为一个整数则宽和高相同\n",
    "    strides=(1, 1), # 横向和纵向的步长,如果为一个整数则横向和纵向相同\n",
    "    padding='valid', # valid:表示不够卷积核大小的块,则丢弃;same表示不够卷积核大小的块就补0,所以输出和输入形状相同\n",
    "    data_format=None, # channels_last为(batch,height,width,channels),channels_first为(batch,channels,height,width)\n",
    "    dilation_rate=(1, 1), # 卷积扩张率，输出形状的宽高要减去相应扩张率\n",
    "    groups=1, # 输入沿通道轴划分的组数\n",
    "    activation=None, # 激活函数,None是线性函数\n",
    "    use_bias=True, # 是否使用偏差量\n",
    "    kernel_initializer='glorot_uniform', # 卷积核的初始化\n",
    "    bias_initializer='zeros', # 偏差向量的初始化。如果是None，则使用默认的初始值。\n",
    "    kernel_regularizer=None, # 卷积核的正则项\n",
    "    bias_regularizer=None, # 偏差向量的正则项\n",
    "    activity_regularizer=None, # 输出的正则函数\n",
    "    kernel_constraint=None, # \n",
    "    bias_constraint=None, # 映射函数，当偏差向量被Optimizer更新后应用到偏差向量上。\n",
    "    **kwargs\n",
    ")\n",
    "\n",
    "池化层：tf.keras.layers.MaxPool2D\n",
    "tf.keras.layers.Conv2D(\n",
    "    filters, kernel_size, strides=(1, 1), padding='valid',\n",
    "    data_format=None, dilation_rate=(1, 1), groups=1, activation=None,\n",
    "    use_bias=True, kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros', kernel_regularizer=None,\n",
    "    bias_regularizer=None, activity_regularizer=None, kernel_constraint=None,\n",
    "    bias_constraint=None, **kwargs\n",
    ")\n",
    "#参数的意思可以看上面的卷积层\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 16s 259us/sample - loss: 0.3641 - accuracy: 0.8926 - val_loss: 0.2121 - val_accuracy: 0.9351\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.1652 - accuracy: 0.9523 - val_loss: 0.1375 - val_accuracy: 0.9580\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.1199 - accuracy: 0.9658 - val_loss: 0.1091 - val_accuracy: 0.9674\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0952 - accuracy: 0.9726 - val_loss: 0.1082 - val_accuracy: 0.9658\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.0788 - accuracy: 0.9775 - val_loss: 0.0947 - val_accuracy: 0.9702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23036b99320>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将输入数据归一化\n",
    "train_data = train_data / 255.0\n",
    "test_data = test_data / 255.0\n",
    "\n",
    "# 优化器使用SGD，学习率取0.5，损失函数使用sparse_categorical_crossentropy\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.5), \n",
    "             loss='sparse_categorical_crossentropy', \n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, train_label, epochs=5,\n",
    "              batch_size=256,\n",
    "              validation_data=(test_data, test_label),\n",
    "              validation_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model.compile:\n",
    "compile(\n",
    "    optimizer='rmsprop', # 字符串形式给出的优化器名字，也可以是函数形式，使用函数形式可以设置学习率、动量和超参数\n",
    "    loss=None, # 字符串形式给出的损失函数的名字，也可以是函数形式\n",
    "    metrics=None, # 标注网络评价指标\n",
    "    loss_weights=None,\n",
    "    weighted_metrics=None, \n",
    "    run_eagerly=None, \n",
    "    **kwargs\n",
    ")\n",
    "\n",
    "model.fit:\n",
    "fit(\n",
    "    x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None,\n",
    "    validation_split=0.0, validation_data=None, shuffle=True, class_weight=None,\n",
    "    sample_weight=None, initial_epoch=0, steps_per_epoch=None,\n",
    "    validation_steps=None, validation_batch_size=None, validation_freq=1,\n",
    "    max_queue_size=10, workers=1, use_multiprocessing=False\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.3821 - accuracy: 0.8832 - val_loss: 0.1524 - val_accuracy: 0.9527\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1296 - accuracy: 0.9604 - val_loss: 0.1537 - val_accuracy: 0.9527\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0892 - accuracy: 0.9729 - val_loss: 0.1563 - val_accuracy: 0.9518\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0682 - accuracy: 0.9790 - val_loss: 0.1054 - val_accuracy: 0.9685\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 0.0538 - accuracy: 0.9835 - val_loss: 0.1760 - val_accuracy: 0.9485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x230373dfc88>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在增加一个全连接层\n",
    "model2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model2.compile(optimizer=tf.keras.optimizers.SGD(lr=0.5), \n",
    "             loss='sparse_categorical_crossentropy', \n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model2.fit(train_data, train_label, epochs=5,\n",
    "              batch_size=256,\n",
    "              validation_data=(test_data, test_label),\n",
    "              validation_freq=1)\n",
    "# 加了一层之后准确率反而降低了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.3751 - accuracy: 0.8835 - val_loss: 0.1941 - val_accuracy: 0.9395\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.1277 - accuracy: 0.9613 - val_loss: 0.1505 - val_accuracy: 0.9512\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.0879 - accuracy: 0.9731 - val_loss: 0.1285 - val_accuracy: 0.9589\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.0669 - accuracy: 0.9800 - val_loss: 0.0746 - val_accuracy: 0.9762\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.0521 - accuracy: 0.9840 - val_loss: 0.0860 - val_accuracy: 0.9740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23037882278>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将上述新添加的全连接层形状修改\n",
    "model3 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model3.compile(optimizer=tf.keras.optimizers.SGD(lr=0.5), \n",
    "             loss='sparse_categorical_crossentropy', \n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model3.fit(train_data, train_label, epochs=5,\n",
    "              batch_size=256,\n",
    "              validation_data=(test_data, test_label),\n",
    "              validation_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "model4 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=6, \n",
    "                           kernel_size=5, \n",
    "                           activation='relu', \n",
    "                           input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.reshape(train_data, (-1, 28, 28, 1))\n",
    "test_data = tf.reshape(test_data, (-1, 28, 28, 1))\n",
    "\n",
    "model4.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.9, momentum=0.0, nesterov=False), \n",
    "             loss='sparse_categorical_crossentropy', \n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000,)\n",
      "(10000, 28, 28, 1)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(train_label.shape)\n",
    "print(test_data.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/5\n",
      "54000/54000 [==============================] - 37s 683us/sample - loss: 2.3089 - accuracy: 0.1066 - val_loss: 2.3115 - val_accuracy: 0.1045\n",
      "Epoch 2/5\n",
      "54000/54000 [==============================] - 30s 562us/sample - loss: 2.3074 - accuracy: 0.1053 - val_loss: 2.3076 - val_accuracy: 0.0960\n",
      "Epoch 3/5\n",
      "54000/54000 [==============================] - 30s 563us/sample - loss: 2.3076 - accuracy: 0.1059 - val_loss: 2.3156 - val_accuracy: 0.1050\n",
      "Epoch 4/5\n",
      "54000/54000 [==============================] - 31s 574us/sample - loss: 2.3076 - accuracy: 0.1059 - val_loss: 2.3087 - val_accuracy: 0.1050\n",
      "Epoch 5/5\n",
      "54000/54000 [==============================] - 30s 565us/sample - loss: 2.3077 - accuracy: 0.1042 - val_loss: 2.3108 - val_accuracy: 0.0952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23059502860>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(train_data, train_label, epochs=5, validation_split=0.1)\n",
    "# 训练结果就跟没训练一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/5\n",
      "54000/54000 [==============================] - 34s 622us/sample - loss: 0.2047 - accuracy: 0.9400 - val_loss: 0.0763 - val_accuracy: 0.9797\n",
      "Epoch 2/5\n",
      "54000/54000 [==============================] - 32s 594us/sample - loss: 0.0688 - accuracy: 0.9792 - val_loss: 0.0605 - val_accuracy: 0.9833\n",
      "Epoch 3/5\n",
      "54000/54000 [==============================] - 32s 600us/sample - loss: 0.0479 - accuracy: 0.9846 - val_loss: 0.0476 - val_accuracy: 0.9870\n",
      "Epoch 4/5\n",
      "54000/54000 [==============================] - 32s 593us/sample - loss: 0.0338 - accuracy: 0.9892 - val_loss: 0.0566 - val_accuracy: 0.9855\n",
      "Epoch 5/5\n",
      "54000/54000 [==============================] - 35s 649us/sample - loss: 0.0258 - accuracy: 0.9916 - val_loss: 0.0522 - val_accuracy: 0.9858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x230380d9518>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=6, \n",
    "                           kernel_size=5, \n",
    "                           activation='relu', \n",
    "                           input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "# 将优化器和学习率换一下\n",
    "model5.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "             loss='sparse_categorical_crossentropy', \n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model5.fit(train_data, train_label, epochs=5, validation_split=0.1)\n",
    "# 修改了优化器和学习率 准确率和之前相差很多\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/5\n",
      "54000/54000 [==============================] - 31s 569us/sample - loss: 1.8414 - accuracy: 0.5220 - val_loss: 0.9106 - val_accuracy: 0.8335\n",
      "Epoch 2/5\n",
      "54000/54000 [==============================] - 30s 548us/sample - loss: 0.6152 - accuracy: 0.8530 - val_loss: 0.3718 - val_accuracy: 0.9075\n",
      "Epoch 3/5\n",
      "54000/54000 [==============================] - 32s 584us/sample - loss: 0.3953 - accuracy: 0.8927 - val_loss: 0.2837 - val_accuracy: 0.9263\n",
      "Epoch 4/5\n",
      "54000/54000 [==============================] - 32s 599us/sample - loss: 0.3321 - accuracy: 0.9060 - val_loss: 0.2458 - val_accuracy: 0.9333\n",
      "Epoch 5/5\n",
      "54000/54000 [==============================] - 36s 664us/sample - loss: 0.2974 - accuracy: 0.9147 - val_loss: 0.2231 - val_accuracy: 0.9387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23056029320>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 试一下只修改学习率 优化器仍然用SGD\n",
    "model6 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=6, \n",
    "                           kernel_size=5, \n",
    "                           activation='relu', \n",
    "                           input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "# 仅修改学习率\n",
    "model6.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.0, nesterov=False), \n",
    "             loss='sparse_categorical_crossentropy', \n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model6.fit(train_data, train_label, epochs=5, validation_split=0.1)\n",
    "# 从结果可以看出确实是学习率造成model4模型训练结果就和没训练一样 \n",
    "# 可能是学习率过大大致欠拟合 甚至模型发散"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面打印各个模型看看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 203,530\n",
      "Trainable params: 203,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 235,146\n",
      "Trainable params: 235,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 6)         156       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 6)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 864)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 256)               221440    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 224,166\n",
      "Trainable params: 224,166\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 6)         156       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 6)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 864)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               221440    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 224,166\n",
      "Trainable params: 224,166\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
